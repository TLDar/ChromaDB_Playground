{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffc9b36-175d-44a2-920e-9014fba70df8",
   "metadata": {},
   "source": [
    "# RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042627c1-ca74-400e-b15c-27d443e6c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c0fc33-befb-4a5f-b00e-1e4108fd8737",
   "metadata": {},
   "source": [
    "## 1 - Load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11332524-ab3f-429f-b1e8-406095cf9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(\"paper.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef1ada-0cb2-4f2b-8375-8d6a00254ef6",
   "metadata": {},
   "source": [
    "## 2 - Split it into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca8ffe-4c39-45df-ac24-9f75994d59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the documents into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656672a-2b8e-4b38-978a-5b4c05121c7a",
   "metadata": {},
   "source": [
    "## 3 - Turn into embeddings and store it into ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aebe0c-0fec-47d4-bc3a-92193f031461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model prooved to be more efficient than other lightweight models when I tried it (lower distances)\n",
    "embedder = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b984dd2-01aa-49d0-b1eb-38a555ab668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_collection = \"rag_collection\"\n",
    "db = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embedding=embedder,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=rag_collection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33931ff3-7f6c-43bc-b455-da9f0e8d4152",
   "metadata": {},
   "source": [
    "## 4 - Query the DB to find the most relevant chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d03ba-a440-4b1f-b175-7a7c42bc2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Represent this sentence for retrieving relevant passages: Who are the authors of this paper?\" # define relevant query right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06679521-13ab-4e54-9dc8-e706780bd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "relevant_chunks = retriever.invoke(query) # looking for the top 5 answers (ie with minimal distance to the query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b033fc4-49cc-4606-b5cb-caf6a5573807",
   "metadata": {},
   "source": [
    "## 5 - Combine relevant chunks into context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75099527-e7c2-4a9a-8f92-a213e4bc6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join([doc.page_content for doc in relevant_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7421f-2212-4951-9e2f-312bf09cb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32cab8-5fad-4f6a-b0c1-e1e77de8e4db",
   "metadata": {},
   "source": [
    "## 6 - connect to the API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f294dd-4c25-4528-9562-58607545296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\") # loading the API key from the .env files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465be98-3871-4c88-90e7-1929e29e5ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the URL to get better results. I tried this with free tier so I didn't get the best models.\n",
    "API_URL_ROBERTA = \"https://api-inference.huggingface.co/models/deepset/roberta-base-squad2\"  # model URL\n",
    "API_URL_MISTRAL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "# Use the API token to set headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "# different call methods I tried with different models.\n",
    "def call_llm_api(query, context):\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    response = requests.post(API_URL, headers=headers, json={\"inputs\": prompt})\n",
    "    return response.json()[0][\"generated_text\"]\n",
    "\n",
    "def call_llm_api_mistral(query, context):\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    response = requests.post(API_URL_MISTRAL, headers=headers, json={\"inputs\": prompt})\n",
    "    try:\n",
    "        data = response.json()\n",
    "        if isinstance(data, list) and \"generated_text\" in data[0]:\n",
    "            return data[0][\"generated_text\"]\n",
    "        elif \"error\" in data:\n",
    "            print(\"API Error:\", data[\"error\"])\n",
    "            return None\n",
    "        else:\n",
    "            print(\"Unexpected response format:\", data)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Exception during parsing:\", e)\n",
    "        print(\"Response text:\", response.text)\n",
    "        return None\n",
    "\n",
    "def call_llm_api_roberta(query, context):\n",
    "    payload = {\n",
    "        \"inputs\": {\n",
    "            \"question\": query,\n",
    "            \"context\": context\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(API_URL_ROBERTA, headers=headers, json=payload)\n",
    "    try:\n",
    "        data = response.json()\n",
    "        if \"answer\" in data:\n",
    "            return data[\"answer\"]\n",
    "        elif \"error\" in data:\n",
    "            print(\"API Error:\", data[\"error\"])\n",
    "            return None\n",
    "        else:\n",
    "            print(\"Unexpected response format:\", data)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Exception during parsing:\", e)\n",
    "        print(\"Response text:\", response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca2b9c-8957-4892-9d20-75e1c6b51163",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = call_llm_api_roberta(query=query, context=context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba4cc2-b1f8-47db-8622-7e4c81fd0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = call_llm_api_mistral(query=query, context=context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399794c1-fe01-4b96-b315-5d533fff48cb",
   "metadata": {},
   "source": [
    "## 7 - try different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f16a0f-0678-4864-a5eb-c4ec184b062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"Represent this sentence for retrieving relevant passages: Provide a concise summary of this paper, highlighting its main objectives, key findings, and conclusions.\" # define relevant query right here\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "relevant_chunks = retriever.invoke(query_1) # looking for the top 5 answers (ie with minimal distance to the query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cbfd4c-27d4-4d72-9803-a376974997e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_1 = \"\\n\".join([doc.page_content for doc in relevant_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67961edd-bae9-42ea-8c5c-aef54b21837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = call_llm_api_mistral(query=query_1, context=context_1)\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d058375-82b8-4022-ada8-1bf5b588ab31",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
