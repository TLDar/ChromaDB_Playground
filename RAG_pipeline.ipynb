{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffc9b36-175d-44a2-920e-9014fba70df8",
   "metadata": {},
   "source": [
    "# RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042627c1-ca74-400e-b15c-27d443e6c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c0fc33-befb-4a5f-b00e-1e4108fd8737",
   "metadata": {},
   "source": [
    "## 1 - Load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11332524-ab3f-429f-b1e8-406095cf9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(\"paper.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef1ada-0cb2-4f2b-8375-8d6a00254ef6",
   "metadata": {},
   "source": [
    "## 2 - Split it into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca8ffe-4c39-45df-ac24-9f75994d59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the documents into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656672a-2b8e-4b38-978a-5b4c05121c7a",
   "metadata": {},
   "source": [
    "## 3 - Turn into embeddings and store it into ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aebe0c-0fec-47d4-bc3a-92193f031461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model prooved to be more efficient than other lightweight models when I tried it (lower distances)\n",
    "embedder = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b984dd2-01aa-49d0-b1eb-38a555ab668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_collection = \"rag_collection\"\n",
    "db = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embedding=embedder,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=rag_collection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33931ff3-7f6c-43bc-b455-da9f0e8d4152",
   "metadata": {},
   "source": [
    "## 4 - Query the DB to find the most relevant chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d03ba-a440-4b1f-b175-7a7c42bc2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Represent this sentence for retrieving relevant passages: who are the authors of this paper ?\" # define relevant query right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06679521-13ab-4e54-9dc8-e706780bd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "relevant_chunks = retriever.invoke(query) # looking for the top 5 answers (ie with minimal distance to the query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b033fc4-49cc-4606-b5cb-caf6a5573807",
   "metadata": {},
   "source": [
    "## 5 - Combine relevant chunks into context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75099527-e7c2-4a9a-8f92-a213e4bc6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join([doc.page_content for doc in relevant_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7421f-2212-4951-9e2f-312bf09cb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32cab8-5fad-4f6a-b0c1-e1e77de8e4db",
   "metadata": {},
   "source": [
    "## 6 - connect to the API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f294dd-4c25-4528-9562-58607545296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\") # loading the API key from the .env files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465be98-3871-4c88-90e7-1929e29e5ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can change the URL to get better results. I tried this with free tier so I didn't get the best models.\n",
    "API_URL_ROBERTA = \"https://api-inference.huggingface.co/models/deepset/roberta-base-squad2\"  # model URL\n",
    "API_URL_MISTRAL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.3\"\n",
    "\n",
    "# Use the API token to set headers\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "# different call methods I tried with different models.\n",
    "def call_llm_api(query, context):\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    response = requests.post(API_URL, headers=headers, json={\"inputs\": prompt})\n",
    "    return response.json()[0][\"generated_text\"]\n",
    "\n",
    "def call_llm_api_mistral(query, context):\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    response = requests.post(API_URL_MISTRAL, headers=headers, json={\"inputs\": prompt})\n",
    "    try:\n",
    "        data = response.json()\n",
    "        if isinstance(data, list) and \"generated_text\" in data[0]:\n",
    "            return data[0][\"generated_text\"]\n",
    "        elif \"error\" in data:\n",
    "            print(\"API Error:\", data[\"error\"])\n",
    "            return None\n",
    "        else:\n",
    "            print(\"Unexpected response format:\", data)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Exception during parsing:\", e)\n",
    "        print(\"Response text:\", response.text)\n",
    "        return None\n",
    "\n",
    "def call_llm_api_roberta(query, context):\n",
    "    payload = {\n",
    "        \"inputs\": {\n",
    "            \"question\": query,\n",
    "            \"context\": context\n",
    "        }\n",
    "    }\n",
    "    response = requests.post(API_URL_ROBERTA, headers=headers, json=payload)\n",
    "    try:\n",
    "        data = response.json()\n",
    "        if \"answer\" in data:\n",
    "            return data[\"answer\"]\n",
    "        elif \"error\" in data:\n",
    "            print(\"API Error:\", data[\"error\"])\n",
    "            return None\n",
    "        else:\n",
    "            print(\"Unexpected response format:\", data)\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(\"Exception during parsing:\", e)\n",
    "        print(\"Response text:\", response.text)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca2b9c-8957-4892-9d20-75e1c6b51163",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = call_llm_api_roberta(query=query, context=context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba4cc2-b1f8-47db-8622-7e4c81fd0b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = call_llm_api_mistral(query=query, context=context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399794c1-fe01-4b96-b315-5d533fff48cb",
   "metadata": {},
   "source": [
    "## 7 - make different queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f16a0f-0678-4864-a5eb-c4ec184b062b",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_1 = \"Represent this sentence for retrieving relevant passages: Provide a concise summary of this paper, highlighting its main objectives, key findings, and conclusions.\" # define relevant query right here\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "relevant_chunks = retriever.invoke(query_1) # looking for the top 5 answers (ie with minimal distance to the query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3cbfd4c-27d4-4d72-9803-a376974997e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_1 = \"\\n\".join([doc.page_content for doc in relevant_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67961edd-bae9-42ea-8c5c-aef54b21837b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = call_llm_api_mistral(query=query_1, context=context_1)\n",
    "print(response_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63c0005-e1e8-4417-89f7-ceb6a4c90fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_2 = \"Represent this sentence for retrieving relevant passages: When was this paper published ?\" # define relevant query right here\n",
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "relevant_chunks = retriever.invoke(query_2) # looking for the top 5 answers (ie with minimal distance to the query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54225ab6-3826-4153-ba15-2e568d9229fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "context_2 = \"\\n\".join([doc.page_content for doc in relevant_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e05231c-9544-4451-8e54-794ac01541d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = call_llm_api_mistral(query=query_2, context=context_2)\n",
    "print(response_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3420fe2-9d66-4bc1-b17a-25d21ee3594b",
   "metadata": {},
   "source": [
    "## 8 - turn responses into a pandas DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21cdc7f0-370e-4572-b158-bb7e6d7304d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Snippet of code to extract the \"Answer\" from the Mistral response. It may be different for other models.\n",
    "\n",
    "# Regular expression pattern to extract answers\n",
    "pattern = r\"Answer:\\s*(.*)\"\n",
    "\n",
    "# Find all matches\n",
    "answer = re.findall(pattern, response)\n",
    "\n",
    "# Display the extracted answers\n",
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54c714d4-39c7-43a0-b3f4-8a8588c87d13",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [\n",
    "    {'question': query, 'answer': re.findall(pattern, response)[0]},\n",
    "    {'question': query_1 , 'answer': re.findall(pattern, response_1)[0]},\n",
    "    {'question': query_2, 'answer': re.findall(pattern, response_2)[0]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb237c2-1f89-4019-960d-0a28f2fed2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(results)\n",
    "df.index = ['author', 'topic', 'date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cbd6ebb-0e02-4e4a-bde9-2e635baa4877",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151371a8-8741-469e-a241-c64a06875dc3",
   "metadata": {},
   "source": [
    "The model performs well when analyzing the paper's topic but is less accurate in identifying author names and publication dates. This discrepancy arises because research papers often include extensive references that list numerous author names and dates, which can confuse the model during extraction. To be fair, it is still able to list the authors accurately but performance could be improved by further processing the paper before making the API call."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
