{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ffc9b36-175d-44a2-920e-9014fba70df8",
   "metadata": {},
   "source": [
    "# RAG pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042627c1-ca74-400e-b15c-27d443e6c205",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import PyMuPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46c0fc33-befb-4a5f-b00e-1e4108fd8737",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1 - Load document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11332524-ab3f-429f-b1e8-406095cf9342",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyMuPDFLoader(\"paper.pdf\")\n",
    "documents = loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26ef1ada-0cb2-4f2b-8375-8d6a00254ef6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2 - Split it into Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ca8ffe-4c39-45df-ac24-9f75994d59d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the documents into chunks\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=500,\n",
    "    chunk_overlap=100\n",
    ")\n",
    "\n",
    "chunks = splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8656672a-2b8e-4b38-978a-5b4c05121c7a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 3 - Turn into embeddings and store it into ChromaDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6aebe0c-0fec-47d4-bc3a-92193f031461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model prooved to be more efficient than other lightweight models when I tried it (lower distances)\n",
    "embedder = HuggingFaceEmbeddings(\n",
    "    model_name=\"BAAI/bge-base-en-v1.5\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b984dd2-01aa-49d0-b1eb-38a555ab668d",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_collection = \"rag_collection\"\n",
    "db = Chroma.from_documents(\n",
    "    chunks,\n",
    "    embedding=embedder,\n",
    "    persist_directory=\"./chroma_db\",\n",
    "    collection_name=rag_collection\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33931ff3-7f6c-43bc-b455-da9f0e8d4152",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 4 - Query the DB to find the most relevant chuncks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25d03ba-a440-4b1f-b175-7a7c42bc2d26",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Represent this sentence for retrieving relevant passages: Who authored this paper?\" # define relevant query right here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06679521-13ab-4e54-9dc8-e706780bd780",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = db.as_retriever(search_kwargs={\"k\": 5})\n",
    "relevant_chunks = retriever.invoke(query) # looking for the top 5 answers (ie with minimal distance to the query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b033fc4-49cc-4606-b5cb-caf6a5573807",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 5 - Combine relevant chunks into context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75099527-e7c2-4a9a-8f92-a213e4bc6f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "context = \"\\n\".join([doc.page_content for doc in relevant_chunks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ff7421f-2212-4951-9e2f-312bf09cb273",
   "metadata": {},
   "outputs": [],
   "source": [
    "context"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f32cab8-5fad-4f6a-b0c1-e1e77de8e4db",
   "metadata": {},
   "source": [
    "## 6 - connect to the API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f294dd-4c25-4528-9562-58607545296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\") # loading the API key from the .env file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1465be98-3871-4c88-90e7-1929e29e5ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "API_URL = \"https://api-inference.huggingface.co/models/mistralai/Mistral-7B-Instruct-v0.1\"  # model URL\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {API_KEY}\"\n",
    "}\n",
    "\n",
    "def call_llm_api(query, context):\n",
    "    prompt = f\"Context: {context}\\n\\nQuestion: {query}\\nAnswer:\"\n",
    "    response = requests.post(API_URL, headers=headers, json={\"inputs\": prompt})\n",
    "    return response.json()[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ca2b9c-8957-4892-9d20-75e1c6b51163",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = call_llm_api(query=query, context=context)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52ba4cc2-b1f8-47db-8622-7e4c81fd0b25",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
